# What AI Tells Candidates About Your Company (And Why It's Probably Wrong)

*Your next best hire just asked ChatGPT about you. Here's why the answer might have lost them forever.*

---

Right now, somewhere, a talented software engineer is deciding whether to apply to your company. They haven't visited your careers page. They haven't checked Glassdoor. They've typed "Is [Your Company] a good place to work?" into ChatGPT — and whatever it said back is now gospel.

Welcome to the new reality of employer branding, where AI is the first impression and you have precisely zero control over what it says.

## The shift nobody's talking about

Candidates have always researched employers before applying. That's not new. What's new is *how* they do it — and it's changed faster than most HR teams have noticed.

Instead of clicking through ten Glassdoor reviews, scanning LinkedIn posts, and reading your carefully crafted careers page, candidates now ask an AI to do all of that for them. One prompt, one synthesised answer, decision made.

Tucker Barker, writing on LinkedIn in November 2025, put it plainly: "The candidates you want to hire are already using AI to research employers. If your brand doesn't perform well in these new discovery channels, you're losing talent before they even visit your careers page."

He's not speculating. The shift from search-and-browse to ask-and-receive is already well underway. And unlike traditional search, where candidates might see your careers page alongside a negative review and weigh the two, AI gives a single authoritative-sounding answer. No nuance. No "on the other hand." Just a verdict.

## The problem: AI makes things up

Here's where it gets properly uncomfortable. AI models don't just summarise what's out there — they hallucinate. They fabricate salary ranges, invent benefits packages, confuse you with similarly named companies, and present outdated information as current fact. All delivered with the unshakeable confidence of someone who's never been wrong in their life.

This isn't theoretical. The evidence is already piling up.

**Air Canada** found this out the hard way in February 2024, when a tribunal ordered it to pay damages after its own AI chatbot gave a passenger incorrect bereavement fare information. Air Canada's defence? It "can't be held liable for information provided by its chatbot." The tribunal, unsurprisingly, [disagreed](https://www.cio.com/article/190888/5-famous-analytics-and-ai-disasters.html).

**New York City's** Microsoft-powered chatbot "MyCity" went further in March 2024, cheerfully telling business owners they could [take a cut of their workers' tips, fire employees who complain about sexual harassment, and serve food that had been nibbled by rodents](https://themarkup.org/news/2024/03/29/nycs-ai-chatbot-tells-businesses-to-break-the-law). All of which is, of course, wildly illegal.

And these are *official* chatbots — ones that organisations deployed on purpose, with some degree of oversight. Now imagine what happens when a general-purpose AI like ChatGPT or Perplexity answers questions about your company using whatever scraps of information it's absorbed from across the internet.

The [KonBriefing AI incidents tracker](https://konbriefing.com/ai/en/ai-incidents-2025.html) has documented dozens of cases across more than fifteen countries where AI-generated misinformation created real legal consequences in 2025 alone. A Czech lawyer was fined CZK 25,000 for filing AI-generated case references that didn't exist. Courts in Belgium, France, Argentina, Poland, and Australia have all dealt with submissions based on hallucinated AI content.

As Dean Chan notes in his LinkedIn analysis of AI hallucinations: "Even if 90% of the AI's answers are correct, the 10% that are hallucinated can dominate public perception."

Ten percent doesn't sound like much. Until it's your salary data that's wrong, your culture that's been mischaracterised, or your company that's been confused with one going through a round of redundancies.

## What this looks like in practice

Let's make it concrete. Here's what AI might get wrong about your company:

**Salary ranges.** AI tools frequently pull salary data from outdated sources, US figures for UK roles, or simply make numbers up. Altis Technology documented in December 2025 how candidates are now using "AI tools (ChatGPT, Perplexity, LinkedIn's AI search) to summarise relevant postings and surface roles that match their skills" — but those summaries regularly include salary data from inconsistent or outdated sources. A candidate walks into your interview expecting £85K because ChatGPT said so. You're offering £65K. The conversation is dead before it starts, and you'll never know why.

**Company culture.** AB&C Creative warned in January 2026: "If your careers site says one thing, your Glassdoor reviews say another and your employees tell a third story, AI will surface the confusion, not the clarity." AI doesn't pick the most recent or most accurate source — it synthesises everything, including that disgruntled review from 2019 and the job ad you forgot to take down.

**Benefits and policies.** Wrong office locations, invented perks, outdated remote working policies. AI doesn't know that you moved offices last year, or that your parental leave policy changed in 2024. It presents whatever it's absorbed as current fact.

**Your existence.** In some cases, AI has been known to simply fabricate details wholesale. If the Chicago Sun-Times and Philadelphia Inquirer can publish AI-generated summer reading lists [recommending books that don't exist by real authors](https://www.cio.com/article/190888/5-famous-analytics-and-ai-disasters.html), what do you think happens when there's limited information about your mid-sized company in the training data?

## The invisible attrition problem

The real damage isn't that AI gets things wrong. It's that you'll never know it happened.

When a candidate reads a bad Glassdoor review, there's at least a chance they'll also see your response, visit your careers page, or ask someone who works there. The information ecosystem has friction and counter-narratives.

AI removes all of that. One answer, delivered instantly, with no link to click through, no counter-argument to weigh, no indication that the information might be wrong. The candidate simply moves on to the next company on their list. No application. No trace. No data point in your ATS showing why they bounced.

Tucker Barker calls this "invisible candidate drop-off," and it's the metric that should terrify talent acquisition teams. Your cost-per-hire goes up. Your time-to-fill extends. Your quality of applicants declines. And the reporting tells you nothing useful about why, because the drop-off happened before your systems even knew the candidate existed.

AB&C Creative frames the vicious cycle neatly: "Poor experiences lead to negative reviews. Negative reviews lead to weaker AI perception. Weaker perception leads to lower visibility and lower candidate trust." Only now, it's not just reviews — it's every piece of information about your company that AI has ever ingested, blended together and served up as truth.

## The double standard nobody wants to talk about

There's a particularly sharp irony here. Many of the same companies losing candidates to AI misinformation are simultaneously using AI to screen those candidates.

A hiring manager on Reddit's r/recruitinghell discovered that [over 35% of applicants had submitted the exact same ChatGPT-generated answer](https://www.reddit.com/r/recruitinghell/comments/1mlve8q/) to their screening questions. The post generated over 1,300 comments, most pointing out the obvious: if employers use AI to filter candidates, candidates will use AI to get past the filter.

Meanwhile, another thread with 140+ comments documented candidates being [scheduled for interviews by AI chatbots — interviews that didn't exist](https://www.reddit.com/r/recruitinghell/comments/1im73pp/). One job seeker described showing up at fast food restaurants three separate times for interviews that had been scheduled by automated systems, only to find nobody was expecting them.

You can't credibly complain about candidates using AI to research you when you're using AI to screen them. And you certainly can't ignore what AI says about your company while deploying it at every other stage of the hiring process.

## Why traditional fixes won't work

Your instinct might be to double down on what's worked before: polish the careers page, respond to Glassdoor reviews, publish more employer brand content on LinkedIn. All perfectly reasonable — and all increasingly insufficient.

VONQ's 2025 report on Generative Engine Optimisation for recruitment spells out why: "AI search platforms like Perplexity, You.com or ChatGPT's web-enabled mode now surface employer brand content — and employers have no optimisation strategy for this."

Single Grain's GEO guide makes the same point from the other direction: "Generative engines add a new twist: they synthesise information from multiple sources, then answer with a single overview or recommendation, often without sending traffic to every source they used."

In other words, AI doesn't care about your beautifully designed careers page. It will read it, mash it together with a Reddit thread from 2021, a salary report from a US database, and a news article about your industry (not even your company specifically), and present the result as "what it's like to work at [Your Company]."

Traditional employer branding assumed you could control the narrative. AI has made that assumption obsolete.

## What you should actually do

Enough doom. Here's what's actionable.

**1. Run the Prompt Test.** This is Tucker Barker's recommendation, and it's the simplest starting point: open ChatGPT, Perplexity, Gemini, and Claude. Ask each one "Is [Your Company] a good place to work?" and "What's the culture like at [Your Company]?" Read what comes back. If you're horrified, you're not alone — but at least now you know.

**2. Audit for consistency.** AB&C Creative's advice is sound: make sure your careers site, your Glassdoor presence, your LinkedIn page, and your employee advocacy all tell the same story. AI will amplify consistency and expose contradictions. If your messaging is fragmented, fix that before worrying about anything else.

**3. Think about GEO, not just SEO.** Your career content needs to be structured in ways that AI can parse accurately. Clear, factual statements about your culture, benefits, salary ranges, and working conditions — written in plain language that AI is less likely to misinterpret or hallucinate around.

**4. Monitor regularly.** The Prompt Test isn't a one-off. AI responses change as models are updated and new data is ingested. What ChatGPT says about you today might be different from what it said three months ago — better or worse. Build it into your quarterly employer brand review.

**5. Accept that this is the new battleground.** The companies that figure out AI employer reputation first will have a structural advantage in talent acquisition for years. As VONQ's research makes clear, there's currently no established playbook for this. That means the early movers get to write it.

## The uncomfortable truth

Here's the bit nobody in employer branding wants to hear: you've spent years and significant budget building an employer brand that candidates increasingly bypass entirely. The carefully curated careers page, the employee testimonial videos, the Glassdoor response strategy — all of it matters less when a candidate's first and only touchpoint is an AI-generated summary they never questioned.

MIT's 2025 research found that only [5% of companies are getting a return on their generative AI investment](https://garymarcus.substack.com/p/three-years-on-chatgpt-still-isnt). But that statistic cuts both ways. If you're not investing in understanding how AI represents your employer brand, you're in the 95% who haven't figured out AI yet — except this time, AI is making decisions about you whether you've invested or not.

The question isn't whether AI will shape how candidates perceive your company. It already does. The question is whether you know what it's saying — and whether you're doing anything about it.

---

*Want to find out what AI actually says about your company? [Run a free audit](#) and see for yourself.*
